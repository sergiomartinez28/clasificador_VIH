{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model_name):\n",
    "    # Cargar el modelo preentrenado\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    # Cargar el tokenizador\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Cargar el dataset desde los archivos CSV temporales\n",
    "    dataset = load_dataset('csv', data_files={'train': 'train_temp_stratify.csv', 'test': 'test_temp_stratify.csv'})\n",
    "\n",
    "    # Funci√≥n de tokenizaci√≥n\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "    # Tokenizar el dataset\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Configuraci√≥n del entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs'\n",
    "    )\n",
    "\n",
    "    # Definir el entrenador\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test']\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    trainer.train()\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "    # Obtener las etiquetas verdaderas y las predicciones\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    # Mostrar m√©tricas\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "    # Extraer valores de la matriz de confusi√≥n\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    print(f'True Negatives: {tn}')\n",
    "    print(f'False Positives: {fp}')\n",
    "    print(f'False Negatives: {fn}')\n",
    "    print(f'True Positives: {tp}')\n",
    "\n",
    "    # Guardar el modelo y el tokenizador\n",
    "    model.save_pretrained(model_name)\n",
    "    tokenizer.save_pretrained(model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 153.79 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 119.50 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 10%|‚ñà         | 5/50 [04:02<31:48, 42.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6485847234725952, 'eval_runtime': 6.1005, 'eval_samples_per_second': 3.278, 'eval_steps_per_second': 0.328, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 20%|‚ñà‚ñà        | 10/50 [06:55<23:45, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5991672873497009, 'eval_runtime': 6.3659, 'eval_samples_per_second': 3.142, 'eval_steps_per_second': 0.314, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [09:34<18:20, 31.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5373362898826599, 'eval_runtime': 5.9271, 'eval_samples_per_second': 3.374, 'eval_steps_per_second': 0.337, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [12:12<15:17, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5017908215522766, 'eval_runtime': 6.023, 'eval_samples_per_second': 3.321, 'eval_steps_per_second': 0.332, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [14:40<11:44, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4658777117729187, 'eval_runtime': 5.9426, 'eval_samples_per_second': 3.366, 'eval_steps_per_second': 0.337, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [17:36<11:37, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4290100634098053, 'eval_runtime': 5.9642, 'eval_samples_per_second': 3.353, 'eval_steps_per_second': 0.335, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [20:50<09:11, 36.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44942933320999146, 'eval_runtime': 5.9943, 'eval_samples_per_second': 3.337, 'eval_steps_per_second': 0.334, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [23:48<05:25, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44322580099105835, 'eval_runtime': 5.8513, 'eval_samples_per_second': 3.418, 'eval_steps_per_second': 0.342, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [26:19<02:21, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4374488890171051, 'eval_runtime': 6.126, 'eval_samples_per_second': 3.265, 'eval_steps_per_second': 0.326, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [28:36<00:00, 34.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43879905343055725, 'eval_runtime': 5.9589, 'eval_samples_per_second': 3.356, 'eval_steps_per_second': 0.336, 'epoch': 10.0}\n",
      "{'train_runtime': 1716.9757, 'train_samples_per_second': 0.466, 'train_steps_per_second': 0.029, 'train_loss': 0.4716197967529297, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "[[8 2]\n",
      " [2 8]]\n",
      "True Negatives: 8\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la funci√≥n con el nombre del modelo deseado\n",
    "train_and_evaluate_model('PlanTL-GOB-ES/roberta-base-biomedical-clinical-es')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/bsc-bio-ehr-es and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 145.08 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 118.01 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 10%|‚ñà         | 5/50 [02:08<19:07, 25.50s/it]\n",
      " 10%|‚ñà         | 5/50 [02:14<19:07, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6326601505279541, 'eval_runtime': 5.9363, 'eval_samples_per_second': 3.369, 'eval_steps_per_second': 0.337, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [04:43<19:05, 28.64s/it]\n",
      " 20%|‚ñà‚ñà        | 10/50 [04:49<19:05, 28.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5768107175827026, 'eval_runtime': 5.8184, 'eval_samples_per_second': 3.437, 'eval_steps_per_second': 0.344, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [07:11<17:24, 29.84s/it]\n",
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [07:17<17:24, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5138899087905884, 'eval_runtime': 5.9943, 'eval_samples_per_second': 3.337, 'eval_steps_per_second': 0.334, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [10:21<18:07, 36.25s/it]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [10:27<18:07, 36.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4473888874053955, 'eval_runtime': 5.8483, 'eval_samples_per_second': 3.42, 'eval_steps_per_second': 0.342, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [13:13<13:52, 33.29s/it]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [13:19<13:52, 33.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4004879891872406, 'eval_runtime': 5.986, 'eval_samples_per_second': 3.341, 'eval_steps_per_second': 0.334, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [15:46<09:57, 29.89s/it]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [15:52<09:57, 29.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35330432653427124, 'eval_runtime': 6.0888, 'eval_samples_per_second': 3.285, 'eval_steps_per_second': 0.328, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [18:37<08:30, 34.02s/it]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [18:43<08:30, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32386285066604614, 'eval_runtime': 5.9189, 'eval_samples_per_second': 3.379, 'eval_steps_per_second': 0.338, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [21:58<06:19, 37.90s/it]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [22:04<06:19, 37.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2984296679496765, 'eval_runtime': 5.8428, 'eval_samples_per_second': 3.423, 'eval_steps_per_second': 0.342, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [24:58<02:56, 35.27s/it]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [25:04<02:56, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2856622040271759, 'eval_runtime': 5.9071, 'eval_samples_per_second': 3.386, 'eval_steps_per_second': 0.339, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [27:37<00:00, 32.93s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [27:43<00:00, 33.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27829232811927795, 'eval_runtime': 5.9719, 'eval_samples_per_second': 3.349, 'eval_steps_per_second': 0.335, 'epoch': 10.0}\n",
      "{'train_runtime': 1663.8055, 'train_samples_per_second': 0.481, 'train_steps_per_second': 0.03, 'train_loss': 0.3824604034423828, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8500\n",
      "Precision: 0.8889\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8421\n",
      "Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "True Negatives: 9\n",
      "False Positives: 1\n",
      "False Negatives: 2\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model('PlanTL-GOB-ES/bsc-bio-ehr-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/bsc-bio-es and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 148.96 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 114.70 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 10%|‚ñà         | 5/50 [01:54<16:58, 22.64s/it]\n",
      " 10%|‚ñà         | 5/50 [02:00<16:58, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6342555284500122, 'eval_runtime': 5.8925, 'eval_samples_per_second': 3.394, 'eval_steps_per_second': 0.339, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [03:56<15:10, 22.77s/it]\n",
      " 20%|‚ñà‚ñà        | 10/50 [04:02<15:10, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5935845971107483, 'eval_runtime': 6.0286, 'eval_samples_per_second': 3.318, 'eval_steps_per_second': 0.332, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [06:50<18:33, 31.82s/it]\n",
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [06:56<18:33, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5344194769859314, 'eval_runtime': 5.7936, 'eval_samples_per_second': 3.452, 'eval_steps_per_second': 0.345, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [09:20<14:06, 28.22s/it]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [09:26<14:06, 28.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48782461881637573, 'eval_runtime': 5.8873, 'eval_samples_per_second': 3.397, 'eval_steps_per_second': 0.34, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [11:41<11:21, 27.26s/it]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [11:47<11:21, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46082741022109985, 'eval_runtime': 5.889, 'eval_samples_per_second': 3.396, 'eval_steps_per_second': 0.34, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [14:00<09:11, 27.58s/it]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [14:06<09:11, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4403974413871765, 'eval_runtime': 5.8368, 'eval_samples_per_second': 3.427, 'eval_steps_per_second': 0.343, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [16:27<07:12, 28.84s/it]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [16:33<07:12, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46200188994407654, 'eval_runtime': 5.8315, 'eval_samples_per_second': 3.43, 'eval_steps_per_second': 0.343, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [19:01<04:47, 28.76s/it]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [19:07<04:47, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4429369866847992, 'eval_runtime': 5.8515, 'eval_samples_per_second': 3.418, 'eval_steps_per_second': 0.342, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [21:31<02:24, 28.81s/it]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [21:37<02:24, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4336150586605072, 'eval_runtime': 6.6131, 'eval_samples_per_second': 3.024, 'eval_steps_per_second': 0.302, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [23:43<00:00, 25.46s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [23:49<00:00, 28.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.437967449426651, 'eval_runtime': 5.9815, 'eval_samples_per_second': 3.344, 'eval_steps_per_second': 0.334, 'epoch': 10.0}\n",
      "{'train_runtime': 1429.9435, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.4726178741455078, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "[[8 2]\n",
      " [2 8]]\n",
      "True Negatives: 8\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model('PlanTL-GOB-ES/bsc-bio-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('../DATASET CLASIFICADO/dataset_large.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['Label'])\n",
    "\n",
    "# Guardar los conjuntos divididos en archivos CSV temporales\n",
    "train_data.to_csv('train_temp_large_stratify.csv', index=False)\n",
    "test_data.to_csv('test_temp_large_stratify.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_large(model_name):\n",
    "    # Cargar el modelo preentrenado\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    # Cargar el tokenizador\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Cargar el dataset desde los archivos CSV temporales\n",
    "    dataset = load_dataset('csv', data_files={'train': 'train_temp_large_stratify.csv', 'test': 'test_temp_large_stratify.csv'})\n",
    "\n",
    "    # Funci√≥n de tokenizaci√≥n\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['Text'], padding='max_length', truncation=True)\n",
    "\n",
    "    # Tokenizar el dataset\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Renombrar las columnas para asegurarnos de que las etiquetas est√°n presentes\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"Label\", \"labels\")\n",
    "\n",
    "    # Configuraci√≥n del entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs'\n",
    "    )\n",
    "\n",
    "    # Definir el entrenador\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test']\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    trainer.train()\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "    # Obtener las etiquetas verdaderas y las predicciones\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "    # Mostrar m√©tricas\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    # Guardar el modelo y el tokenizador\n",
    "    model.save_pretrained(f\"{model_name}-large\")\n",
    "    tokenizer.save_pretrained(f\"{model_name}-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 325 examples [00:00, 11607.29 examples/s]\n",
      "Generating test split: 82 examples [00:00, 10262.06 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 242.25 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 187.74 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|‚ñà         | 21/210 [09:21<1:07:31, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2831881046295166, 'eval_runtime': 25.0198, 'eval_samples_per_second': 3.277, 'eval_steps_per_second': 0.24, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|‚ñà‚ñà        | 42/210 [19:19<59:34, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14821089804172516, 'eval_runtime': 24.8577, 'eval_samples_per_second': 3.299, 'eval_steps_per_second': 0.241, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 30%|‚ñà‚ñà‚ñà       | 63/210 [29:09<53:25, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12969444692134857, 'eval_runtime': 25.0004, 'eval_samples_per_second': 3.28, 'eval_steps_per_second': 0.24, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 84/210 [38:53<43:50, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16634182631969452, 'eval_runtime': 24.8488, 'eval_samples_per_second': 3.3, 'eval_steps_per_second': 0.241, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 105/210 [48:50<37:05, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15200179815292358, 'eval_runtime': 24.8986, 'eval_samples_per_second': 3.293, 'eval_steps_per_second': 0.241, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 126/210 [58:21<27:28, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19665752351284027, 'eval_runtime': 24.6833, 'eval_samples_per_second': 3.322, 'eval_steps_per_second': 0.243, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 147/210 [1:07:57<20:45, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18835368752479553, 'eval_runtime': 24.8418, 'eval_samples_per_second': 3.301, 'eval_steps_per_second': 0.242, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 168/210 [1:17:23<14:21, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20475420355796814, 'eval_runtime': 24.8607, 'eval_samples_per_second': 3.298, 'eval_steps_per_second': 0.241, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 189/210 [1:27:22<08:03, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20111684501171112, 'eval_runtime': 24.7385, 'eval_samples_per_second': 3.315, 'eval_steps_per_second': 0.243, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [1:37:28<00:00, 27.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20014069974422455, 'eval_runtime': 25.9517, 'eval_samples_per_second': 3.16, 'eval_steps_per_second': 0.231, 'epoch': 10.0}\n",
      "{'train_runtime': 5848.238, 'train_samples_per_second': 0.556, 'train_steps_per_second': 0.036, 'train_loss': 0.10056460244315012, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:20<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9048\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la funci√≥n con el nombre del modelo deseado\n",
    "train_and_evaluate_model_large('PlanTL-GOB-ES/roberta-base-biomedical-clinical-es')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 248.88 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 191.80 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 10%|‚ñà         | 21/210 [09:03<1:01:16, 19.45s/it]\n",
      " 10%|‚ñà         | 21/210 [09:29<1:01:16, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15091797709465027, 'eval_runtime': 25.8157, 'eval_samples_per_second': 3.176, 'eval_steps_per_second': 0.232, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 42/210 [18:18<57:41, 20.61s/it]  \n",
      " 20%|‚ñà‚ñà        | 42/210 [18:44<57:41, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14807073771953583, 'eval_runtime': 25.9153, 'eval_samples_per_second': 3.164, 'eval_steps_per_second': 0.232, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 63/210 [28:11<51:40, 21.09s/it]  \n",
      " 30%|‚ñà‚ñà‚ñà       | 63/210 [28:37<51:40, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15885797142982483, 'eval_runtime': 25.6307, 'eval_samples_per_second': 3.199, 'eval_steps_per_second': 0.234, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 84/210 [37:36<45:06, 21.48s/it]  \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 84/210 [38:00<45:06, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18214403092861176, 'eval_runtime': 24.6696, 'eval_samples_per_second': 3.324, 'eval_steps_per_second': 0.243, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 105/210 [47:34<37:21, 21.35s/it] \n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 105/210 [47:59<37:21, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18754495680332184, 'eval_runtime': 24.6624, 'eval_samples_per_second': 3.325, 'eval_steps_per_second': 0.243, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 126/210 [57:08<28:17, 20.21s/it]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 126/210 [57:33<28:17, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1998073309659958, 'eval_runtime': 25.2297, 'eval_samples_per_second': 3.25, 'eval_steps_per_second': 0.238, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 147/210 [1:07:01<21:53, 20.84s/it]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 147/210 [1:07:27<21:53, 20.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20879000425338745, 'eval_runtime': 25.5066, 'eval_samples_per_second': 3.215, 'eval_steps_per_second': 0.235, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 168/210 [1:16:22<14:12, 20.31s/it]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 168/210 [1:16:48<14:12, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20973293483257294, 'eval_runtime': 25.7873, 'eval_samples_per_second': 3.18, 'eval_steps_per_second': 0.233, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 189/210 [1:25:41<06:58, 19.93s/it]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 189/210 [1:26:07<06:58, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22559534013271332, 'eval_runtime': 25.8526, 'eval_samples_per_second': 3.172, 'eval_steps_per_second': 0.232, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [1:34:46<00:00, 20.19s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [1:35:13<00:00, 27.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23101471364498138, 'eval_runtime': 26.0532, 'eval_samples_per_second': 3.147, 'eval_steps_per_second': 0.23, 'epoch': 10.0}\n",
      "{'train_runtime': 5713.0321, 'train_samples_per_second': 0.569, 'train_steps_per_second': 0.037, 'train_loss': 0.0669925190153576, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:20<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9048\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9048\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model_large('PlanTL-GOB-ES/bsc-bio-ehr-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 250.77 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 197.03 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 10%|‚ñà         | 21/210 [08:13<1:05:37, 20.83s/it]\n",
      " 10%|‚ñà         | 21/210 [08:38<1:05:37, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22292762994766235, 'eval_runtime': 24.8409, 'eval_samples_per_second': 3.301, 'eval_steps_per_second': 0.242, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 42/210 [16:33<47:47, 17.07s/it]  \n",
      " 20%|‚ñà‚ñà        | 42/210 [16:58<47:47, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14695627987384796, 'eval_runtime': 24.655, 'eval_samples_per_second': 3.326, 'eval_steps_per_second': 0.243, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 63/210 [24:47<42:25, 17.32s/it]  \n",
      " 30%|‚ñà‚ñà‚ñà       | 63/210 [25:12<42:25, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15568889677524567, 'eval_runtime': 24.7276, 'eval_samples_per_second': 3.316, 'eval_steps_per_second': 0.243, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 84/210 [32:44<33:52, 16.13s/it]  \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 84/210 [33:09<33:52, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16700312495231628, 'eval_runtime': 24.694, 'eval_samples_per_second': 3.321, 'eval_steps_per_second': 0.243, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 105/210 [40:39<30:02, 17.17s/it]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 105/210 [41:03<30:02, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.171054869890213, 'eval_runtime': 24.7667, 'eval_samples_per_second': 3.311, 'eval_steps_per_second': 0.242, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 126/210 [48:56<23:14, 16.60s/it]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 126/210 [49:21<23:14, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18239150941371918, 'eval_runtime': 24.6484, 'eval_samples_per_second': 3.327, 'eval_steps_per_second': 0.243, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 147/210 [14:09:28<1:39:29, 94.76s/it]     \n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 147/210 [14:09:54<1:39:29, 94.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18920879065990448, 'eval_runtime': 26.2921, 'eval_samples_per_second': 3.119, 'eval_steps_per_second': 0.228, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 168/210 [14:21:10<18:33, 26.52s/it]  \n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 168/210 [14:21:36<18:33, 26.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22810699045658112, 'eval_runtime': 25.8889, 'eval_samples_per_second': 3.167, 'eval_steps_per_second': 0.232, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 189/210 [14:31:34<07:23, 21.11s/it]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 189/210 [14:31:59<07:23, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23574219644069672, 'eval_runtime': 24.8678, 'eval_samples_per_second': 3.297, 'eval_steps_per_second': 0.241, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [14:41:22<00:00, 23.66s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [14:41:47<00:00, 251.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2346363514661789, 'eval_runtime': 24.728, 'eval_samples_per_second': 3.316, 'eval_steps_per_second': 0.243, 'epoch': 10.0}\n",
      "{'train_runtime': 52907.0586, 'train_samples_per_second': 0.061, 'train_steps_per_second': 0.004, 'train_loss': 0.10913990565708705, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:19<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9474\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9000\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model_large('PlanTL-GOB-ES/bsc-bio-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def train_and_evaluate_model_large(model_name):\n",
    "    # Verificar si CUDA est√° disponible y seleccionar el dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Cargar el modelo preentrenado\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    model.to(device)  # Mover el modelo a la GPU si est√° disponible\n",
    "\n",
    "    # Cargar el tokenizador\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Cargar el dataset desde los archivos CSV temporales\n",
    "    dataset = load_dataset('csv', data_files={'train': 'train_temp_large_stratify.csv', 'test': 'test_temp_large_stratify.csv'})\n",
    "\n",
    "    # Funci√≥n de tokenizaci√≥n\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['Text'], padding='max_length', truncation=True)\n",
    "\n",
    "    # Tokenizar el dataset\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Renombrar las columnas para asegurarnos de que las etiquetas est√°n presentes\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"Label\", \"labels\")\n",
    "\n",
    "    # Configuraci√≥n del entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,  # Evaluar cada 500 pasos\n",
    "        learning_rate=3e-5,  # Ajuste de la tasa de aprendizaje\n",
    "        per_device_train_batch_size=8,  # Reducir el tama√±o del lote para ahorrar memoria\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=15,  # Ajuste del n√∫mero de √©pocas\n",
    "        weight_decay=0.01,  # Ajuste del decay de peso\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=50,  # Registrar cada 50 pasos\n",
    "        save_steps=500,  # Guardar cada 500 pasos\n",
    "        save_total_limit=3,  # Mantener solo los 3 √∫ltimos checkpoints\n",
    "        fp16=True,  # Utilizar precisi√≥n mixta para reducir el uso de memoria\n",
    "        gradient_accumulation_steps=4  # Acumular gradientes para simular un tama√±o de lote mayor\n",
    "    )\n",
    "\n",
    "    # Definir el entrenador\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test'],\n",
    "        compute_metrics=compute_metrics  # A√±adir funci√≥n para calcular m√©tricas personalizadas\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    trainer.train()\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "    # Obtener las etiquetas verdaderas y las predicciones\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Mostrar m√©tricas\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "    # Extraer valores de la matriz de confusi√≥n\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    print(f'True Negatives: {tn}')\n",
    "    print(f'False Positives: {fp}')\n",
    "    print(f'False Negatives: {fn}')\n",
    "    print(f'True Positives: {tp}')\n",
    "\n",
    "    # Generar un nombre √∫nico para el guardado del modelo\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_directory = f\"{model_name}-large-{timestamp}\"\n",
    "\n",
    "    # Guardar el modelo y el tokenizador\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(p.label_ids, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 50/150 [00:52<01:39,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.205, 'grad_norm': 0.21594415605068207, 'learning_rate': 1.9999999999999998e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 100/150 [01:41<00:48,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0167, 'grad_norm': 0.06789407879114151, 'learning_rate': 9.999999999999999e-06, 'epoch': 9.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [02:30<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0044, 'grad_norm': 0.8298442959785461, 'learning_rate': 0.0, 'epoch': 14.63}\n",
      "{'train_runtime': 150.2359, 'train_samples_per_second': 32.449, 'train_steps_per_second': 0.998, 'train_loss': 0.07537646303574244, 'epoch': 14.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9048\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9048\n",
      "Confusion Matrix:\n",
      "[[59  2]\n",
      " [ 2 19]]\n",
      "True Negatives: 59\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 19\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model_large('PlanTL-GOB-ES/roberta-base-biomedical-clinical-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 243.38 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 185.81 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 50/150 [00:49<01:38,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1341, 'grad_norm': 0.1790304183959961, 'learning_rate': 2.02e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 100/150 [01:38<00:48,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0275, 'grad_norm': 0.08087718486785889, 'learning_rate': 1.02e-05, 'epoch': 9.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [02:27<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0065, 'grad_norm': 0.08358662575483322, 'learning_rate': 2.0000000000000002e-07, 'epoch': 14.63}\n",
      "{'train_runtime': 147.4722, 'train_samples_per_second': 33.057, 'train_steps_per_second': 1.017, 'train_loss': 0.05604925930500031, 'epoch': 14.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9634\n",
      "Precision: 0.9500\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9268\n",
      "Confusion Matrix:\n",
      "[[60  1]\n",
      " [ 2 19]]\n",
      "True Negatives: 60\n",
      "False Positives: 1\n",
      "False Negatives: 2\n",
      "True Positives: 19\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model_large('PlanTL-GOB-ES/bsc-bio-ehr-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 260.86 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 189.88 examples/s]\n",
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 50/150 [00:49<01:37,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2015, 'grad_norm': 0.199437215924263, 'learning_rate': 1.9999999999999998e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 100/150 [01:37<00:48,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.038, 'grad_norm': 0.08665261417627335, 'learning_rate': 1.02e-05, 'epoch': 9.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [02:26<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0194, 'grad_norm': 0.08960975706577301, 'learning_rate': 2.0000000000000002e-07, 'epoch': 14.63}\n",
      "{'train_runtime': 146.6529, 'train_samples_per_second': 33.242, 'train_steps_per_second': 1.023, 'train_loss': 0.08629438916842143, 'epoch': 14.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9474\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9000\n",
      "Confusion Matrix:\n",
      "[[60  1]\n",
      " [ 3 18]]\n",
      "True Negatives: 60\n",
      "False Positives: 1\n",
      "False Negatives: 3\n",
      "True Positives: 18\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model_large('PlanTL-GOB-ES/bsc-bio-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Cargar el modelo preentrenado\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    model.to(device)  # Mover el modelo a la GPU si est√° disponible\n",
    "\n",
    "    # Cargar el tokenizador\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Cargar el dataset desde los archivos CSV temporales\n",
    "    dataset = load_dataset('csv', data_files={'train': 'train_temp_stratify.csv', 'test': 'test_temp_stratify.csv'})\n",
    "\n",
    "    # Funci√≥n de tokenizaci√≥n\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "    # Tokenizar el dataset\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Configuraci√≥n del entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,  # Evaluar cada 500 pasos\n",
    "        learning_rate=3e-5,  # Ajuste de la tasa de aprendizaje\n",
    "        per_device_train_batch_size=8,  # Reducir el tama√±o del lote para ahorrar memoria\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=15,  # Ajuste del n√∫mero de √©pocas\n",
    "        weight_decay=0.01,  # Ajuste del decay de peso\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=50,  # Registrar cada 50 pasos\n",
    "        save_steps=500,  # Guardar cada 500 pasos\n",
    "        save_total_limit=3,  # Mantener solo los 3 √∫ltimos checkpoints\n",
    "        fp16=True,  # Utilizar precisi√≥n mixta para reducir el uso de memoria\n",
    "        gradient_accumulation_steps=4  # Acumular gradientes para simular un tama√±o de lote mayor\n",
    "    )\n",
    "\n",
    "    # Definir el entrenador\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test'],\n",
    "        compute_metrics=compute_metrics  # A√±adir funci√≥n para calcular m√©tricas personalizadas\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    trainer.train()\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "    # Obtener las etiquetas verdaderas y las predicciones\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Mostrar m√©tricas\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "    # Extraer valores de la matriz de confusi√≥n\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    print(f'True Negatives: {tn}')\n",
    "    print(f'False Positives: {fp}')\n",
    "    print(f'False Negatives: {fn}')\n",
    "    print(f'True Positives: {tp}')\n",
    "\n",
    "    # Generar un nombre √∫nico para el guardado del modelo\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_directory = f\"{model_name}-{timestamp}\"\n",
    "\n",
    "    # Guardar el modelo y el tokenizador\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(p.label_ids, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:29<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 29.913, 'train_samples_per_second': 40.116, 'train_steps_per_second': 1.003, 'train_loss': 0.12969179153442384, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6500\n",
      "Precision: 0.6154\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.6957\n",
      "Confusion Matrix:\n",
      "[[5 5]\n",
      " [2 8]]\n",
      "True Negatives: 5\n",
      "False Positives: 5\n",
      "False Negatives: 2\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model('PlanTL-GOB-ES/roberta-base-biomedical-clinical-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:30<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 30.0983, 'train_samples_per_second': 39.869, 'train_steps_per_second': 0.997, 'train_loss': 0.08999994595845541, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9000\n",
      "Precision: 0.8333\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9091\n",
      "Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "True Negatives: 8\n",
      "False Positives: 2\n",
      "False Negatives: 0\n",
      "True Positives: 10\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model('PlanTL-GOB-ES/bsc-bio-ehr-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:30<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 30.1246, 'train_samples_per_second': 39.835, 'train_steps_per_second': 0.996, 'train_loss': 0.13567263285319012, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 27.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7000\n",
      "Precision: 0.6250\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.7692\n",
      "Confusion Matrix:\n",
      "[[ 4  6]\n",
      " [ 0 10]]\n",
      "True Negatives: 4\n",
      "False Positives: 6\n",
      "False Negatives: 0\n",
      "True Positives: 10\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model('PlanTL-GOB-ES/bsc-bio-es')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d766878ac6b4cb495d055bd03540b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d45a97096745b9aa63749b9a188c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e53716916941b98e763ba36b0b4e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da626621e8d47ebb72f012859bcb034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "\n",
    "# Ruta a la carpeta donde se encuentra el modelo guardado\n",
    "paths_s = ['bsc-bio-ehr-es', 'bsc-bio-es', 'roberta-base-biomedical-clinical-es']\n",
    "paths_l = ['bsc-bio-ehr-es-large', 'bsc-bio-es-large', 'roberta-base-biomedical-clinical-es-large']\n",
    "base_path = 'PlanTL-GOB-ES'\n",
    "dataset_s = load_dataset('csv', data_files={'train': 'train_temp_stratify.csv', 'test': 'test_temp_stratify.csv'})\n",
    "dataset_l = load_dataset('csv', data_files={'train': 'train_temp_large_stratify.csv', 'test': 'test_temp_large_stratify.csv'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de elementos en el CSV: 407\n",
      "Tipos de datos de cada columna:\n",
      "Text     object\n",
      "Label     int64\n",
      "dtype: object\n",
      "\n",
      "Recuento de cada etiqueta:\n",
      "Label\n",
      "0    305\n",
      "1    102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "file_path = '../transformers/dataset_large.csv'  # Reemplaza esto con la ruta a tu archivo CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Obtener la cantidad de elementos (filas)\n",
    "num_elements = len(df)\n",
    "\n",
    "# Obtener el tipo de datos de cada columna\n",
    "column_types = df.dtypes\n",
    "\n",
    "# Obtener el recuento de cada etiqueta (label)\n",
    "# Reemplaza 'Label' con el nombre de la columna que contiene las etiquetas en tu CSV\n",
    "label_counts = df['Label'].value_counts()\n",
    "\n",
    "# Mostrar la cantidad de elementos, el tipo de datos de cada columna y el recuento de etiquetas\n",
    "print(f'Número de elementos en el CSV: {num_elements}')\n",
    "print('Tipos de datos de cada columna:')\n",
    "print(column_types)\n",
    "print('\\nRecuento de cada etiqueta:')\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset S - Train set:\n",
      "Class 0: 40\n",
      "Class 1: 40\n",
      "\n",
      "Dataset S - Test set:\n",
      "Class 0: 10\n",
      "Class 1: 10\n",
      "\n",
      "Dataset L - Train set:\n",
      "Class 0: 244\n",
      "Class 1: 81\n",
      "\n",
      "Dataset L - Test set:\n",
      "Class 0: 61\n",
      "Class 1: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_classes_s(dataset, dataset_name):\n",
    "    for split in ['train', 'test']:\n",
    "        # Convertir el dataset en un DataFrame de pandas para facilitar el conteo\n",
    "        df = pd.DataFrame(dataset[split])\n",
    "        \n",
    "        # Contar los elementos por clase\n",
    "        class_counts = df['label'].value_counts().to_dict()\n",
    "        \n",
    "        # Asegurarse de que ambas clases 0 y 1 estén presentes en el conteo\n",
    "        class_counts = {label: class_counts.get(label, 0) for label in [0, 1]}\n",
    "        \n",
    "        print(f\"{dataset_name} - {split.capitalize()} set:\")\n",
    "        print(f\"Class 0: {class_counts[0]}\")\n",
    "        print(f\"Class 1: {class_counts[1]}\")\n",
    "        print()\n",
    "\n",
    "def count_classes_l(dataset, dataset_name):\n",
    "    for split in ['train', 'test']:\n",
    "        # Convertir el dataset en un DataFrame de pandas para facilitar el conteo\n",
    "        df = pd.DataFrame(dataset[split])\n",
    "        \n",
    "        # Contar los elementos por clase\n",
    "        class_counts = df['Label'].value_counts().to_dict()\n",
    "        \n",
    "        # Asegurarse de que ambas clases 0 y 1 estén presentes en el conteo\n",
    "        class_counts = {label: class_counts.get(label, 0) for label in [0, 1]}\n",
    "        \n",
    "        print(f\"{dataset_name} - {split.capitalize()} set:\")\n",
    "        print(f\"Class 0: {class_counts[0]}\")\n",
    "        print(f\"Class 1: {class_counts[1]}\")\n",
    "        print()\n",
    "\n",
    "# Contar y mostrar los resultados para cada dataset\n",
    "count_classes_s(dataset_s, 'Dataset S')\n",
    "count_classes_l(dataset_l, 'Dataset L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el dataset original:\n",
      "Label\n",
      "0    305\n",
      "1    102\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases en el dataset de entrenamiento:\n",
      "Label\n",
      "0    244\n",
      "1     81\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases en el dataset de prueba:\n",
      "Label\n",
      "0    61\n",
      "1    21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset_large = pd.read_csv('../transformers/dataset_large.csv')\n",
    "\n",
    "# Verificar la distribución de clases en el dataset original\n",
    "print(\"Distribución de clases en el dataset original:\")\n",
    "print(dataset_large['Label'].value_counts())\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba de manera estratificada\n",
    "train_df, test_df = train_test_split(dataset_large, test_size=0.2, stratify=dataset_large['Label'], random_state=42)\n",
    "\n",
    "# Verificar la distribución de clases en el dataset de entrenamiento y prueba\n",
    "print(\"Distribución de clases en el dataset de entrenamiento:\")\n",
    "print(train_df['Label'].value_counts())\n",
    "print(\"Distribución de clases en el dataset de prueba:\")\n",
    "print(test_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_s():\n",
    "    for path in paths_s:\n",
    "        model_path = f'{base_path}/{path}'\n",
    "        print(f'MODELO: {model_path}')\n",
    "        # Cargar el modelo desde la carpeta local\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "        # Cargar el tokenizador desde la carpeta local\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "        \n",
    "        # Tokenizar el dataset\n",
    "        tokenized_datasets = dataset_s.map(tokenize_function, batched=True)\n",
    "\n",
    "        # Verificar los nombres de las columnas\n",
    "        print(tokenized_datasets['train'].column_names)\n",
    "        print(tokenized_datasets['test'].column_names)\n",
    "\n",
    "\n",
    "        # Configuración del entrenador solo para realizar predicciones (sin entrenamiento)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            per_device_eval_batch_size=16,\n",
    "        )\n",
    "\n",
    "        # Definir el entrenador\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            eval_dataset=tokenized_datasets['test']\n",
    "        )\n",
    "\n",
    "        # Obtener las predicciones del modelo\n",
    "        predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "        # Obtener las etiquetas verdaderas y las predicciones\n",
    "        y_true = predictions.label_ids\n",
    "        y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "        # Calcular la matriz de confusión\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1 Score: {f1:.4f}')\n",
    "        print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "        # Extraer valores de la matriz de confusión\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "        print(f'True Negatives: {tn}')\n",
    "        print(f'False Positives: {fp}')\n",
    "        print(f'False Negatives: {fn}')\n",
    "        print(f'True Positives: {tp}')\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_l():\n",
    "    for path in paths_l:\n",
    "        model_path = f'{base_path}/{path}'\n",
    "        print(f'MODELO: {model_path}')\n",
    "        # Cargar el modelo desde la carpeta local\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "        # Cargar el tokenizador desde la carpeta local\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples['Text'], padding='max_length', truncation=True)\n",
    "        \n",
    "        # Tokenizar el dataset\n",
    "        tokenized_datasets = dataset_l.map(tokenize_function, batched=True)\n",
    "        \n",
    "        tokenized_datasets = tokenized_datasets.rename_column(\"Label\", \"labels\")\n",
    "\n",
    "        # Verificar los nombres de las columnas\n",
    "        print(tokenized_datasets['train'].column_names)\n",
    "        print(tokenized_datasets['test'].column_names)\n",
    "\n",
    "\n",
    "        # Configuración del entrenador solo para realizar predicciones (sin entrenamiento)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            per_device_eval_batch_size=16,\n",
    "        )\n",
    "\n",
    "        # Definir el entrenador\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            eval_dataset=tokenized_datasets['test']\n",
    "        )\n",
    "\n",
    "        # Obtener las predicciones del modelo\n",
    "        predictions = trainer.predict(tokenized_datasets['test'])\n",
    "        \n",
    "        # Obtener las etiquetas verdaderas y las predicciones\n",
    "        y_true = predictions.label_ids\n",
    "        y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "\n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "        # Calcular la matriz de confusión\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1 Score: {f1:.4f}')\n",
    "        print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "        # Extraer valores de la matriz de confusión\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "        print(f'True Negatives: {tn}')\n",
    "        print(f'False Positives: {fp}')\n",
    "        print(f'False Negatives: {fn}')\n",
    "        print(f'True Positives: {tp}')\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET PEQUEÑO\n",
      "MODELO: PlanTL-GOB-ES/bsc-bio-ehr-es\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ff87714ea7467a8bc04b0ce4ce8fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3ab9233e614c8a808e0bd751052543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'attention_mask']\n",
      "['text', 'label', 'input_ids', 'attention_mask']\n",
      "WARNING:tensorflow:From C:\\Users\\serma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d2448a415a4b88b5b193e619dcceec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8500\n",
      "Precision: 0.8889\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8421\n",
      "Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "True Negatives: 9\n",
      "False Positives: 1\n",
      "False Negatives: 2\n",
      "True Positives: 8\n",
      "\n",
      "\n",
      "MODELO: PlanTL-GOB-ES/bsc-bio-es\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267b558e0cc14c979250750128211935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5d665874fa47e8a7ccfd604c32a5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'attention_mask']\n",
      "['text', 'label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2834571cc5349c782ba7d1dec70a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "[[8 2]\n",
      " [2 8]]\n",
      "True Negatives: 8\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 8\n",
      "\n",
      "\n",
      "MODELO: PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3276fce9699540cab2c7f62fdc92a5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441c14243edf46bcb7038f2239e6e536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'attention_mask']\n",
      "['text', 'label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f775a9ed63a49019f599ec14406427d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "[[8 2]\n",
      " [2 8]]\n",
      "True Negatives: 8\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DATASET PEQUEÑO')\n",
    "metrics_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET GRANDE\n",
      "MODELO: PlanTL-GOB-ES/bsc-bio-ehr-es-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70570ffd9ec147f69b557cc6a4545e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/325 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9ded1712e84134b8d80c3a4d209191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'labels', 'input_ids', 'attention_mask']\n",
      "['Text', 'labels', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed822cbd47847558862f68449fd65a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9048\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9048\n",
      "Confusion Matrix:\n",
      "[[59  2]\n",
      " [ 2 19]]\n",
      "True Negatives: 59\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 19\n",
      "\n",
      "\n",
      "MODELO: PlanTL-GOB-ES/bsc-bio-es-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1346f5a51945bbb1b0f01acbef34e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/325 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8490cd941fef4b478e1c11bd7f8a7c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'labels', 'input_ids', 'attention_mask']\n",
      "['Text', 'labels', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61778aca90b34cbebb112083057e7050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9474\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9000\n",
      "Confusion Matrix:\n",
      "[[60  1]\n",
      " [ 3 18]]\n",
      "True Negatives: 60\n",
      "False Positives: 1\n",
      "False Negatives: 3\n",
      "True Positives: 18\n",
      "\n",
      "\n",
      "MODELO: PlanTL-GOB-ES/roberta-base-biomedical-clinical-es-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd05cf6d576f4328a2422f490798759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/325 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f347431b34298b363317ed29e1618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'labels', 'input_ids', 'attention_mask']\n",
      "['Text', 'labels', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c351985a85141c79650528113aa9a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.9048\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9048\n",
      "Confusion Matrix:\n",
      "[[59  2]\n",
      " [ 2 19]]\n",
      "True Negatives: 59\n",
      "False Positives: 2\n",
      "False Negatives: 2\n",
      "True Positives: 19\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DATASET GRANDE')\n",
    "metrics_l()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

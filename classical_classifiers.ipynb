{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorimos clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from clasificadorVIH import ClasificadorVIH\n",
    "\n",
    "clasificador = ClasificadorVIH()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntuaciones de los indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  Group1  Group2  Group3  Group4  Group5  Group6  Group7  Group8\n",
      "0   9.20     0.0     0.0     0.0    10.8     1.3     2.5     0.0     0.0\n",
      "1   5.20     0.0     0.0     0.0     2.8     1.3     2.5     0.0     0.0\n",
      "2   7.65     0.0     0.0     0.0     3.3     1.3     4.7     0.0     0.0\n",
      "3   8.30     0.0     0.0     0.0     2.8     1.3     5.6     0.0     0.0\n",
      "4   2.70     4.7     0.0     2.5     2.8     1.3     7.3     5.8     4.3\n",
      "(100, 9)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['Score', 'Group1', 'Group2', 'Group3', 'Group4', 'Group5','Group6', 'Group7', 'Group8']\n",
    "data = {name: [] for name in column_names}\n",
    "for i in range(100):\n",
    "    g1, g2, g3, g4, g5, g6, g7, g8, score = clasificador.symptoms_analysis(i)\n",
    "    data['Score'].append(score)\n",
    "    data['Group1'].append(g1[1])\n",
    "    data['Group2'].append(g2[1])\n",
    "    data['Group3'].append(g3[1])\n",
    "    data['Group4'].append(g4)\n",
    "    data['Group5'].append(g5)\n",
    "    data['Group6'].append(g6[1])\n",
    "    data['Group7'].append(g7[1])\n",
    "    data['Group8'].append(g8[1])\n",
    "\n",
    "# Crear DataFrame con los datos recopilados\n",
    "df_X = pd.DataFrame(data)\n",
    "\n",
    "# Visualización de las primeras filas del DataFrame para verificar\n",
    "print(df_X.head())\n",
    "print(df_X.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución en el conjunto de entrenamiento:\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Distribución en el conjunto de prueba:\n",
      "1.0    0.5\n",
      "0.0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos asegurando el balanceo\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, y_true, test_size=0.2, random_state=42, stratify=y_true)\n",
    "\n",
    "# Verificar la distribución después de la división\n",
    "print(\"Distribución en el conjunto de entrenamiento:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "print(\"Distribución en el conjunto de prueba:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.9 0.7 0.7 0.7 0.6 0.7 0.5 0.9 0.7 0.8]\n",
      "Media de cross-validation: 0.72\n",
      "Confusion Matrix:\n",
      "[[39 11]\n",
      " [17 33]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.78      0.74        50\n",
      "         1.0       0.75      0.66      0.70        50\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.72      0.72      0.72       100\n",
      "weighted avg       0.72      0.72      0.72       100\n",
      "\n",
      "Recall: 0.6600\n",
      "Precision: 0.7500\n",
      "F1-score: 0.7021\n",
      "Accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Crear el modelo de Regresión Logística\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Aplicar 10-fold cross-validation usando StratifiedKFold para mantener la proporción de clases\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_logistic = cross_val_score(logistic_model, df_X, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_logistic)\n",
    "print(\"Media de cross-validation:\", scores_logistic.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(logistic_model, df_X, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_logistic = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_logistic)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_logistic.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.9 0.7 0.8 0.8 0.3 0.7 0.5 0.6 0.5 0.5]\n",
      "Media de cross-validation: 0.6300000000000001\n",
      "Confusion Matrix:\n",
      "[[33 17]\n",
      " [20 30]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.66      0.64        50\n",
      "         1.0       0.64      0.60      0.62        50\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.63      0.63      0.63       100\n",
      "weighted avg       0.63      0.63      0.63       100\n",
      "\n",
      "Recall: 0.6000\n",
      "Precision: 0.6383\n",
      "F1-score: 0.6186\n",
      "Accuracy: 0.6300\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Crear el modelo de Árbol de Decisión\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Aplicar 10-fold cross-validation usando StratifiedKFold para mantener la proporción de clases\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_tree = cross_val_score(tree_model, df_X, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_tree)\n",
    "print(\"Media de cross-validation:\", scores_tree.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(tree_model, df_X, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_tree = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_tree)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_tree.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de soporte vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.9 0.6 0.7 0.7 0.6 0.6 0.6 0.9 0.7 0.8]\n",
      "Media de cross-validation: 0.71\n",
      "Confusion Matrix:\n",
      "[[37 13]\n",
      " [16 34]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.74      0.72        50\n",
      "         1.0       0.72      0.68      0.70        50\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.71      0.71      0.71       100\n",
      "weighted avg       0.71      0.71      0.71       100\n",
      "\n",
      "Recall: 0.6800\n",
      "Precision: 0.7234\n",
      "F1-score: 0.7010\n",
      "Accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Crear el modelo de Máquina de Soporte Vectorial (SVM)\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Aplicar 10-fold cross-validation usando StratifiedKFold para mantener la proporción de clases\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_svm = cross_val_score(svm_model, df_X, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_svm)\n",
    "print(\"Media de cross-validation:\", scores_svm.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(svm_model, df_X, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_svm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_svm)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_svm.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texto de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from text_processor import TextProcessor\n",
    "\n",
    "\n",
    "def get_text_and_labels():\n",
    "    text_processor = TextProcessor()\n",
    "    texts = []\n",
    "    y_true = []\n",
    "    for i in range(0, 50):\n",
    "        text = text_processor.get_text_from_file('datasets', i)\n",
    "        label = 0\n",
    "        texts.append(preprocess_text(text))\n",
    "        y_true.append(label)\n",
    "    \n",
    "\n",
    "    for i in range(50, 100):\n",
    "        text = text_processor.get_text_from_file('datasets', i)\n",
    "        label = 1\n",
    "        texts.append(preprocess_text(text))\n",
    "        y_true.append(label)\n",
    "        \n",
    "    return texts, y_true\n",
    "\n",
    "# Preprocesar el texto (puedes ajustar esta función según tus necesidades)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Obtener los textos y las etiquetas verdaderas\n",
    "texts, y_true = get_text_and_labels()\n",
    "\n",
    "# Convertir textos a vectores TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000)  # Puedes ajustar max_features según tus necesidades\n",
    "X_tfidf = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "# Convertir y_true a una serie de pandas para facilitar el manejo\n",
    "y_true = pd.Series(y_true)\n",
    "\n",
    "# Dividir los datos asegurando el balanceo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_true, test_size=0.2, random_state=42, stratify=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.6 0.8 0.8 1.  1.  0.7 0.9 0.9 0.9 0.8]\n",
      "Media de cross-validation: 0.8400000000000001\n",
      "Confusion Matrix:\n",
      "[[46  4]\n",
      " [12 38]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        50\n",
      "           1       0.90      0.76      0.83        50\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.85      0.84      0.84       100\n",
      "weighted avg       0.85      0.84      0.84       100\n",
      "\n",
      "Recall: 0.7600\n",
      "Precision: 0.9048\n",
      "F1-score: 0.8261\n",
      "Accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_logreg = cross_val_score(logreg_model, X_tfidf, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_logreg)\n",
    "print(\"Media de cross-validation:\", scores_logreg.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(logreg_model, X_tfidf, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_logreg = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_logreg)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_logreg.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.8 0.5 0.7 1.  1.  0.9 1.  0.8 0.8 0.7]\n",
      "Media de cross-validation: 0.82\n",
      "Confusion Matrix:\n",
      "[[41  9]\n",
      " [ 9 41]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        50\n",
      "           1       0.82      0.82      0.82        50\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.82      0.82      0.82       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n",
      "Recall: 0.8200\n",
      "Precision: 0.8200\n",
      "F1-score: 0.8200\n",
      "Accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Aplicar 10-fold cross-validation usando StratifiedKFold para mantener la proporción de clases\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_dt = cross_val_score(decision_tree_model, X_tfidf, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_dt)\n",
    "print(\"Media de cross-validation:\", scores_dt.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(decision_tree_model, X_tfidf, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_dt = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dt)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_dt.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de cross-validation: [0.6 0.7 0.8 1.  1.  0.7 0.9 0.9 0.9 0.8]\n",
      "Media de cross-validation: 0.8300000000000001\n",
      "Confusion Matrix:\n",
      "[[46  4]\n",
      " [13 37]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84        50\n",
      "           1       0.90      0.74      0.81        50\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.84      0.83      0.83       100\n",
      "weighted avg       0.84      0.83      0.83       100\n",
      "\n",
      "Recall: 0.7400\n",
      "Precision: 0.9024\n",
      "F1-score: 0.8132\n",
      "Accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Aplicar 10-fold cross-validation usando StratifiedKFold para mantener la proporción de clases\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_svm = cross_val_score(svm_model, X_tfidf, y_true, cv=skf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Métricas de cross-validation:\", scores_svm)\n",
    "print(\"Media de cross-validation:\", scores_svm.mean())\n",
    "\n",
    "# Evaluar el modelo en el conjunto de datos completo con cross-validation\n",
    "y_pred = cross_val_predict(svm_model, X_tfidf, y_true, cv=skf)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm_svm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_svm)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Calcular TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_svm.ravel()\n",
    "\n",
    "# Calcular Recall, Precision, F1-score\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
